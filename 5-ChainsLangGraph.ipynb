{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Using LangGraph\n",
    "In this section we will see how we can build a simple chain using Langgraph that uses 4 important concepts\n",
    "\n",
    "- How to use chat messages as our graph state\n",
    "- How to use chat models in graph nodes\n",
    "- How to bind tools to our LLM in chat models\n",
    "- How to execute the tools call in our graph nodes "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:09:27.934158Z",
     "start_time": "2025-12-27T14:09:27.919779Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use chat messages as our graph state\n",
    "##### Messages\n",
    "\n",
    "We can use messages which can be used to capture different roles within a conversation.\n",
    "LangChain has various message types including HumanMessage, AIMessage, SystemMessage and ToolMessage.\n",
    "These represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call.\n",
    "\n",
    "Every message have these important components.\n",
    "\n",
    "- content - content of the message\n",
    "- name - Specify the name of author\n",
    "- response_metadata - optionally, a dict of metadata (e.g., often populated by model provider for AIMessages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:09:47.259067Z",
     "start_time": "2025-12-27T14:09:47.253818Z"
    }
   },
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "from pprint import pprint\n",
    "\n",
    "messages=[AIMessage(content=f\"Please tell me how can I help\",name=\"LLMModel\")]\n",
    "messages.append(HumanMessage(content=f\"I want to learn coding\",name=\"John\"))\n",
    "messages.append(AIMessage(content=f\"Which programming language you want to learn\",name=\"LLMModel\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn python programming language\",name=\"John\"))\n",
    "\n",
    "for message in messages:\n",
    "    message.pretty_print()\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Name: LLMModel\n",
      "\n",
      "Please tell me how can I help\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "Name: John\n",
      "\n",
      "I want to learn coding\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Name: LLMModel\n",
      "\n",
      "Which programming language you want to learn\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "Name: John\n",
      "\n",
      "I want to learn python programming language\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Models\n",
    "\n",
    "We can use the sequence of message as input with the chatmodels using LLM's and OPENAI."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:11:04.641652Z",
     "start_time": "2025-12-27T14:11:03.856913Z"
    }
   },
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"qwen-3-32b\")\n",
    "result=llm.invoke(messages)"
   ],
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'The model `qwen-3-32b` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNotFoundError\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_groq\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChatGroq\n\u001B[32m      2\u001B[39m llm=ChatGroq(model=\u001B[33m\"\u001B[39m\u001B[33mqwen-3-32b\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m result=\u001B[43mllm\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AgenticAI\\AgenticAI-LangChain-LangGraph\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001B[39m, in \u001B[36mBaseChatModel.invoke\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    384\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    385\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m    386\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    391\u001B[39m     **kwargs: Any,\n\u001B[32m    392\u001B[39m ) -> AIMessage:\n\u001B[32m    393\u001B[39m     config = ensure_config(config)\n\u001B[32m    394\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[32m    395\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAIMessage\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    396\u001B[39m         cast(\n\u001B[32m    397\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mChatGeneration\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m--> \u001B[39m\u001B[32m398\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    399\u001B[39m \u001B[43m                \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    400\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    401\u001B[39m \u001B[43m                \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcallbacks\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    402\u001B[39m \u001B[43m                \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtags\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    403\u001B[39m \u001B[43m                \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    404\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_name\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    405\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    406\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    407\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m.generations[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m],\n\u001B[32m    408\u001B[39m         ).message,\n\u001B[32m    409\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AgenticAI\\AgenticAI-LangChain-LangGraph\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001B[39m, in \u001B[36mBaseChatModel.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m   1108\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   1109\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_prompt\u001B[39m(\n\u001B[32m   1110\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1114\u001B[39m     **kwargs: Any,\n\u001B[32m   1115\u001B[39m ) -> LLMResult:\n\u001B[32m   1116\u001B[39m     prompt_messages = [p.to_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m-> \u001B[39m\u001B[32m1117\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AgenticAI\\AgenticAI-LangChain-LangGraph\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001B[39m, in \u001B[36mBaseChatModel.generate\u001B[39m\u001B[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    924\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(input_messages):\n\u001B[32m    925\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    926\u001B[39m         results.append(\n\u001B[32m--> \u001B[39m\u001B[32m927\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    928\u001B[39m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    929\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    930\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    931\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    932\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    933\u001B[39m         )\n\u001B[32m    934\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    935\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AgenticAI\\AgenticAI-LangChain-LangGraph\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001B[39m, in \u001B[36mBaseChatModel._generate_with_cache\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1219\u001B[39m     result = generate_from_stream(\u001B[38;5;28miter\u001B[39m(chunks))\n\u001B[32m   1220\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m inspect.signature(\u001B[38;5;28mself\u001B[39m._generate).parameters.get(\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1221\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1222\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1223\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1224\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1225\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AgenticAI\\AgenticAI-LangChain-LangGraph\\.venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:593\u001B[39m, in \u001B[36mChatGroq._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m    588\u001B[39m message_dicts, params = \u001B[38;5;28mself\u001B[39m._create_message_dicts(messages, stop)\n\u001B[32m    589\u001B[39m params = {\n\u001B[32m    590\u001B[39m     **params,\n\u001B[32m    591\u001B[39m     **kwargs,\n\u001B[32m    592\u001B[39m }\n\u001B[32m--> \u001B[39m\u001B[32m593\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmessage_dicts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    594\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._create_chat_result(response, params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AgenticAI\\AgenticAI-LangChain-LangGraph\\.venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:461\u001B[39m, in \u001B[36mCompletions.create\u001B[39m\u001B[34m(self, messages, model, citation_options, compound_custom, disable_tool_validation, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m    241\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m    242\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    243\u001B[39m     *,\n\u001B[32m   (...)\u001B[39m\u001B[32m    300\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = not_given,\n\u001B[32m    301\u001B[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001B[32m    302\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    303\u001B[39m \u001B[33;03m    Creates a model response for the given chat conversation.\u001B[39;00m\n\u001B[32m    304\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    459\u001B[39m \u001B[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001B[39;00m\n\u001B[32m    460\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m461\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    462\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/openai/v1/chat/completions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    463\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    464\u001B[39m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m    465\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    466\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    467\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcitation_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcitation_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    468\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcompound_custom\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompound_custom\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    469\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdisable_tool_validation\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisable_tool_validation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    470\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdocuments\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    471\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mexclude_domains\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude_domains\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    472\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfrequency_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    473\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunction_call\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    474\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunctions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    475\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43minclude_domains\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_domains\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    476\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43minclude_reasoning\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_reasoning\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    477\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogit_bias\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    478\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    479\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_completion_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    480\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    481\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    482\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mn\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    483\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mparallel_tool_calls\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    484\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpresence_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    485\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mreasoning_effort\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    486\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mreasoning_format\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    487\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mresponse_format\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    488\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msearch_settings\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msearch_settings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    489\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mseed\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    490\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mservice_tier\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    491\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstop\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    492\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstore\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    493\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    494\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtemperature\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    495\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtool_choice\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    496\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtools\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    497\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_logprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    498\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_p\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    499\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    500\u001B[39m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    501\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    502\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    503\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    504\u001B[39m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m    505\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    506\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    507\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    508\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    509\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AgenticAI\\AgenticAI-LangChain-LangGraph\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1242\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1228\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1229\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1230\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1237\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1238\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1239\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1240\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1241\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1242\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\AgenticAI\\AgenticAI-LangChain-LangGraph\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1044\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1041\u001B[39m             err.response.read()\n\u001B[32m   1043\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1044\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1046\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1048\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mNotFoundError\u001B[39m: Error code: 404 - {'error': {'message': 'The model `qwen-3-32b` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}}"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 446,\n",
       "  'prompt_tokens': 75,\n",
       "  'total_tokens': 521,\n",
       "  'completion_time': 2.23,\n",
       "  'prompt_time': 0.006678778,\n",
       "  'queue_time': 0.242182835,\n",
       "  'total_time': 2.236678778},\n",
       " 'model_name': 'qwen-2.5-32b',\n",
       " 'system_fingerprint': 'fp_35f92f8282',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools\n",
    "Tools can be integrated with the LLM models to interact with external systems. External systems can be API's, third party tools.\n",
    "\n",
    "Whenever a query is asked the model can choose to call the tool and this query is based on the \n",
    "natural language input and this will return an output that matches the tool's schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a:int,b:int)-> int:\n",
    "    \"\"\" Add a and b\n",
    "    Args:\n",
    "        a (int): first int\n",
    "        b (int): second int\n",
    "\n",
    "    Returns:\n",
    "        int\n",
    "    \"\"\"\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000293FFF34920>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000029380144EF0>, model_name='qwen-2.5-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Binding tool with llm\n",
    "\n",
    "llm_with_tools=llm.bind_tools([add])\n",
    "\n",
    "tool_call=llm_with_tools.invoke([HumanMessage(content=f\"What is 2 plus 2\",name=\"Krish\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 2, 'b': 2},\n",
       "  'id': 'call_bxje',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using messages as state"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:12:29.005879Z",
     "start_time": "2025-12-27T14:12:29.000947Z"
    }
   },
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class State(TypedDict):\n",
    "    message:list[AnyMessage]"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducers\n",
    "Now, we have a minor problem!\n",
    "\n",
    "As we discussed, each node will return a new value for our state key messages.\n",
    "\n",
    "But, this new value will override the prior messages value.\n",
    "\n",
    "As our graph runs, we want to append messages to our messages state key.\n",
    "\n",
    "We can use reducer functions to address this.\n",
    "\n",
    "Reducers allow us to specify how state updates are performed.\n",
    "\n",
    "If no reducer function is specified, then it is assumed that updates to the key should override it as we saw before.\n",
    "\n",
    "But, to append messages, we can use the pre-built add_messages reducer.\n",
    "\n",
    "This ensures that any messages are appended to the existing list of messages.\n",
    "\n",
    "We simply need to annotate our messages key with the add_messages reducer function as metadata."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:12:31.378285Z",
     "start_time": "2025-12-27T14:12:31.373135Z"
    }
   },
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "class State(TypedDict):\n",
    "    messages:Annotated[list[AnyMessage],add_messages]"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducers with add_messages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:12:39.372557Z",
     "start_time": "2025-12-27T14:12:39.366743Z"
    }
   },
   "source": [
    "initial_messages=[AIMessage(content=f\"Please tell me how can I help\",name=\"LLMModel\")]\n",
    "initial_messages.append(HumanMessage(content=f\"I want to learn coding\",name=\"John\"))\n",
    "initial_messages"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Please tell me how can I help', additional_kwargs={}, response_metadata={}, name='LLMModel'),\n",
       " HumanMessage(content='I want to learn coding', additional_kwargs={}, response_metadata={}, name='John')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:12:43.720251Z",
     "start_time": "2025-12-27T14:12:43.706278Z"
    }
   },
   "source": [
    "ai_message=AIMessage(content=f\"Which programming language you want to learn\",name=\"LLMModel\")\n",
    "ai_message"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Which programming language you want to learn', additional_kwargs={}, response_metadata={}, name='LLMModel')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:12:48.232344Z",
     "start_time": "2025-12-27T14:12:48.223303Z"
    }
   },
   "source": [
    "### Reducers add_messages is to append instead of override\n",
    "add_messages(initial_messages,ai_message)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Please tell me how can I help', additional_kwargs={}, response_metadata={}, name='LLMModel', id='2f2c2d5c-b3ad-49ca-ac9b-f4446b92a5ac'),\n",
       " HumanMessage(content='I want to learn coding', additional_kwargs={}, response_metadata={}, name='John', id='4de52447-0981-41ae-9ff4-75985cfadd80'),\n",
       " AIMessage(content='Which programming language you want to learn', additional_kwargs={}, response_metadata={}, name='LLMModel', id='8adaff85-cc3e-4186-89db-bf2f1e1ee3fb')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:12:53.918672Z",
     "start_time": "2025-12-27T14:12:53.914560Z"
    }
   },
   "source": [
    "## chatbot node functionality\n",
    "def llm_tool(state:State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T14:13:16.348290Z",
     "start_time": "2025-12-27T14:12:55.254465Z"
    }
   },
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "builder=StateGraph(State)\n",
    "\n",
    "builder.add_node(\"llm_tool\",llm_tool)\n",
    "\n",
    "builder.add_edge(START,\"llm_tool\")\n",
    "builder.add_edge(\"llm_tool\",END)\n",
    "\n",
    "graph=builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is 2 plus 2\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_hky1)\n",
      " Call ID: call_hky1\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 2\n"
     ]
    }
   ],
   "source": [
    "## invocation\n",
    "\n",
    "messages=graph.invoke({\"messages\":\"What is 2 plus 2\"})\n",
    "\n",
    "for message in messages[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "\n",
    "builder=StateGraph(State)\n",
    "\n",
    "## Add nodes\n",
    "\n",
    "builder.add_node(\"llm_tool\",llm_tool)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Add Edge\n",
    "builder.add_edge(START,\"llm_tool\")\n",
    "builder.add_conditional_edges(\n",
    "    \"llm_tool\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge(\"tools\",END)\n",
    "\n",
    "\n",
    "graph_builder = builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is 2 plus 2\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_txad)\n",
      " Call ID: call_txad\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 2\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: add\n",
      "\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "## invocation\n",
    "\n",
    "messages=graph.invoke({\"messages\":\"What is 2 plus 2\"})\n",
    "\n",
    "for message in messages[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What Machine Learning\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Machine Learning is a subset of artificial intelligence that involves building systems that can learn from and make decisions based on data. It focuses on the development of programs and algorithms that can access data and use it to learn for themselves. The primary aim of machine learning is to allow computers to learn automatically without human intervention or assistance and adjust actions accordingly.\n",
      "\n",
      "Machine learning algorithms are often categorized into three main types:\n",
      "\n",
      "1. Supervised Learning: This type of learning involves a training process where the algorithm is provided with labeled data. The goal is to learn a mapping from inputs to outputs, and then be able to predict outputs for new, unseen data.\n",
      "\n",
      "2. Unsupervised Learning: In this type, the algorithm is given data that is not labeled and the goal is to find hidden patterns or intrinsic structures in input data.\n",
      "\n",
      "3. Reinforcement Learning: This type of learning involves an agent that interacts with an environment, producing actions and discovering errors or rewards. The goal is to learn a policy that optimizes the number of rewards over time.\n",
      "\n",
      "Machine learning is used in a wide range of applications, including but not limited to, image and speech recognition, recommendation systems, natural language processing, and autonomous driving.\n"
     ]
    }
   ],
   "source": [
    "messages=graph.invoke({\"messages\":\"What Machine Learning\"})\n",
    "\n",
    "for message in messages[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
